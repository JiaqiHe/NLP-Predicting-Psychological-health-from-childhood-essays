{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018 Shared Tasks\n",
    "#### The results shown here represent top 2000 words selection, in SVC, we choose 200\n",
    "#### If you would like to have top 200 words in this draft, just change 2000 to 200 or any other numbers you want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import collections\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_modified.p', 'rb') as fp:\n",
    "    data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anx_score = []\n",
    "for k in data:\n",
    "    anx_score.append(data[k]['anxiety'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data depression distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 5594,\n",
       " 1.0: 1945,\n",
       " 2.0: 876,\n",
       " 3.0: 404,\n",
       " 4.0: 213,\n",
       " 5.0: 144,\n",
       " 6.0: 96,\n",
       " 7.0: 72,\n",
       " 8.0: 56,\n",
       " 9.0: 26,\n",
       " 10.0: 19,\n",
       " 11.0: 5,\n",
       " 12.0: 5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict((x,anx_score.count(x)) for x in set(anx_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_essay = []\n",
    "data_anxie = []\n",
    "data_depre = []\n",
    "for k in data:\n",
    "    data_essay.append(data[k]['essay'])\n",
    "    data_anxie.append(data[k]['anxiety'])\n",
    "    data_depre.append(data[k]['depression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regular expression of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_all = []\n",
    "for k in data_essay:\n",
    "    words = re.compile('\\w+').findall(k)\n",
    "    words = [x.lower() for x in words]\n",
    "    words_all += words\n",
    "counts = collections.Counter(words_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top N words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('go', 21261),\n",
       " ('would', 18337),\n",
       " ('like', 13796),\n",
       " ('work', 12507),\n",
       " ('get', 12163),\n",
       " ('children', 8541),\n",
       " ('home', 8273),\n",
       " ('one', 7107),\n",
       " ('house', 6748),\n",
       " ('time', 6110),\n",
       " ('got', 5950),\n",
       " ('years', 5681),\n",
       " ('name', 5569),\n",
       " ('job', 5566),\n",
       " ('live', 5550),\n",
       " ('old', 5386),\n",
       " ('two', 5226),\n",
       " ('married', 4740),\n",
       " ('going', 4740),\n",
       " ('school', 4608)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counts.most_common()[:-21:-1]\n",
    "### Here we just showed the top 20 words, and in this workflow we used 2000\n",
    "### You can use whatever you want\n",
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_count = [k[0] for k in counts.most_common(2000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    wor = re.compile('\\w+').findall(datum)\n",
    "    wor = [x.lower() for x in wor]\n",
    "    cou = collections.Counter(wor)\n",
    "    # for 20 words\n",
    "    # feat = [1, cou['go'], cou['would'], cou['like'], cou['work'], cou['get'], cou['children'], cou['home'], cou['one'], cou['house'], cou['time'], cou['got'], cou['years'], cou['name'], cou['job'], cou['live'], cou['old'], cou['two'], cou['married'], cou['going'], cou['school']]\n",
    "    feat = [1] + [cou[k] for k in top_n_count]\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_essay = [feature(datum) for datum in data_essay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_depre = []\n",
    "for k in data_depre:\n",
    "    if k == 0:\n",
    "        new_data_depre.append(0)\n",
    "    else:\n",
    "        new_data_depre.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data to training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_essay, new_data_depre, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner(x,y):\n",
    "    return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "    loglikelihood = 0\n",
    "    for i in range(len(X)):\n",
    "        logit = inner(X[i], theta)\n",
    "        loglikelihood -= np.log(1 + np.exp(-logit))\n",
    "        if not y[i]:\n",
    "            loglikelihood -= logit\n",
    "    for k in range(len(theta)):\n",
    "        loglikelihood -= lam * theta[k]*theta[k]\n",
    "    # for debugging\n",
    "    # print(\"ll =\" + str(loglikelihood))\n",
    "    return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "    dl = [0]*len(theta)\n",
    "    for i in range(len(X)):\n",
    "        logit = inner(X[i], theta)\n",
    "        for k in range(len(theta)):\n",
    "            dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "            if not y[i]:\n",
    "                dl[k] -= X[i][k]\n",
    "    for k in range(len(theta)):\n",
    "        dl[k] -= lam*2*theta[k]\n",
    "    return np.array([-x for x in dl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lam):\n",
    "    theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X_train[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = train(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-03 23:30:38.249417\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "currentDT = datetime.datetime.now()\n",
    "print (str(currentDT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(theta, dataset_x, dataset_y):\n",
    "    scores = [inner(theta,k) for k in dataset_x]\n",
    "    predictions = [1 if s > 0 else 0 for s in scores]\n",
    "    #correct = [(a==b) for (a,b) in zip(predictions,dataset_y)]\n",
    "    correct = [(a==b) for (a,b) in zip(predictions,dataset_y)]\n",
    "    acc = sum(correct) * 1.0 / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of validation set is 0.5887275023681717\n"
     ]
    }
   ],
   "source": [
    "print('accuracy of validation set is', performance(theta, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of validation set is 0.5825056071771868\n"
     ]
    }
   ],
   "source": [
    "print('accuracy of validation set is', performance(theta, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [1 if s > 0 else 0 for s in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = [(a==b) for (a,b) in zip(predictions,y_test)]\n",
    "acc = sum(correct) * 1.0 / len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5709708426786286"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mod = [s > 0 for s in y_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7813388064414272"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance(theta, X_train, y_train_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mod = [s > 0 for s in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5709708426786286"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance(theta, X_test, y_test_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
